import os
import pandas as pd
import os
import json 
from pathlib import Path
import sympy as sp
import re
from tqdm import tqdm

"""
The difference between this script and create_ladder_sympy.py is that this script creates the dataset from variants from the MIT_variants directory in
the repository MITIntegrationBee, whereas create_ladder_sympy.py creates the dataset from variants from the ladder_variants directory in the repository, which
were generated by Akira.
"""

TEST_QUESTIONS = [
    "integrate(x + (x**0.5)/(1 + (x**0.5)), x)",
    
    "integrate(exp(x + 1)/(exp(x) + 1), x)",
    
    "integrate((3*sin(x) - sin(3*x))**(1/3), x)",
    
    "integrate(log(x**(log(x**x)))/x**2, x",
    
    "integrate(cos(20*x)*sin(25*x), x, -pi/2, pi/2)",
    
    "integrate(sin(x)*cos(x)*tan(x)*cot(x)*sec(x)*csc(x), x, 0, 2*pi)",
    
    "integrate((x*log(x)*cos(x) - sin(x))/(x*log(x)**2), x)",
    
    "integrate((2*x - 1 + log(2*x)), x, 1, 2)",
    
    "integrate(x**2024*(1 - x**2025)**2025, x, 0, 1)",
    
    "integrate((x - 1/2)*(x - 1)*x, x, 0, 10)",
    
    "integrate(floor(x)/2, x, 0, 20)",
    
    "integrate((exp(2*x)*(x**2 + x))/(x*exp(x)*4 + 1), x)",
    
    "integrate(sec(x)**4 - tan(x)**4, x)",
    
    "integrate(sqrt(x*(1 - x)), x, 0, 1)",
    
    "integrate(sin(4*x)*cos(x)/(cos(2*x)*sin(x)), x)",
    
    "integrate(sin(x)*sinh(x), x)",
    
    "integrate(sin(x)*cos(pi/3 - x), x, 0, pi/3)",
    
    "integrate((cos(x) + cos(x + 2*pi/3) + cos(x - 2*pi/3))**2, x)",
    
    "integrate(sum((-1)**k*x**(2*k)), x, 0, 1)",
    # Add more integrals as needed
]


def variants_to_parquet(train_questions, test_questions, output_path: str) -> None:
    samples = []
    test_samples = []
    # Define an instruction for the incorrect questions.
    instruction_following = "<instruction> Solve the following integral. Provide ONLY your antiderivative as a valid Python sympy expression e.g  <answer>cos(x**2)+ ln(x)+(1/3)*x**3</answer> wrapped in a <answer> tags. Importantly, put * between terms you want to multiply! Show your full working out before solving, don't include any constants of integration. DO NOT OUTPUT IN LATEX FORMAT. OUTPUT IN SYMPY in <answer> tags. </instruction>"

    # Loop over each question.
    for idx, train_question in enumerate(train_questions):
        # Build the prompt by combining the question with the instruction.
        prompt_content = f"{train_question}\n{instruction_following}"
        
        # Build a sample dictionary
        sample = {
            "data_source": "llm_judge_integration_nosympy",
            "prompt": [{
                "role": "user",
                "content": prompt_content
            }],
            "ability": "integration",
            "reward_model": {
                "style": "rule",
                "ground_truth": train_question
            },
            "extra_info": {
                "question_index": idx,
                "question_id": train_question
            }
        }
        samples.append(sample)

    # Create test samples using the base question
    for idx, test_question in enumerate(test_questions):
        prompt_content = f"{test_question}\n{instruction_following}"
        test_sample = {
            "data_source": "integration_numeric",
            "prompt": [{
                "role": "user", 
                "content": prompt_content
            }],
            "ability": "integration",
            "reward_model": {
                "style": "rule",
                "ground_truth": test_question
            },
            "extra_info": {
                "question_index": idx,
                "question_id": test_question
            }
        }
        test_samples.append(test_sample)
    
    # Define a local output directory and ensure it exists.
    os.makedirs(output_path, exist_ok=True)

    # Save the samples to JSON files
    import json
    with open(os.path.join(output_path, f'train.json'), 'w') as f:
        json.dump(samples, f, indent=4)
    with open(os.path.join(output_path, f'test.json'), 'w') as f:
        json.dump(test_samples, f, indent=4)
    
    # Save the samples to Parquet files
    import pandas as pd
    df = pd.DataFrame(samples)
    df.to_parquet(os.path.join(output_path, f'train.parquet'))
    
    test_df = pd.DataFrame(test_samples)
    test_df.to_parquet(os.path.join(output_path, f'test.parquet'))
    
    print(f"Train samples saved to {output_path}/train.parquet")
    print(f"Test samples saved to {output_path}/test.parquet")

def extract_integral(ground_truth: str) -> str:
    return ground_truth[10:-4]

def preprocess_candidate_solution(solution: str) -> str:
    solution = re.sub(r'\*\s*\.\.\.', '', solution)
    solution = solution.replace("...", "")
    solution = solution.replace(r"\(", "").replace(r"\)", "")
    solution = solution.replace("$", "")
    solution = solution.replace("\\arctan", "atan")
    solution = solution.replace("\\arcsin", "asin")
    solution = solution.replace("\\arccos", "acos")
    solution = solution.replace("arccos", "acos")
    solution = solution.replace("arcsin", "asin")
    solution = solution.replace("arctan", "atan")
    solution = solution.replace("e^", "2.718**")
    solution = solution.replace("^", "**")
    solution = solution.replace("\\ln", "log")
    solution = re.sub(r'e\*\*([^*]+)', r'exp(\1)', solution)
    solution = re.sub(r"\+?\s*C\b", "", solution)
    return solution.strip() or "0"

def sympy_correct_formatting(solution: str) -> bool:
    import signal
    import time
    
    x, k = sp.symbols('x k')
    locals_dict = {
        'x': x,
        'k': k,
        'C': 0,
        'integrate': sp.integrate,
        'Sum': sp.Sum,   # Use Sum for symbolic summation.
        'sum': sp.Sum,   # Allow 'sum' to be an alias.
        'pi': sp.pi,
        'sin': sp.sin,
        'cos': sp.cos,
        'tan': sp.tan,
        'log': sp.log,
        'exp': sp.exp,
        'sqrt': sp.sqrt,
        'atan': sp.atan,
        'asin': sp.asin,
        'acos': sp.acos
    }
    
    # Define timeout handler
    class TimeoutException(Exception):
        pass
    
    def timeout_handler(signum, frame):
        raise TimeoutException("Expression parsing timed out")
    
    try:
        candidate = preprocess_candidate_solution(solution)
        
        # Set timeout (5 seconds)
        signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(5)
        
        try:
            candidate_expr = sp.parse_expr(candidate, local_dict=locals_dict)
            print(candidate_expr)
            # Cancel the alarm if parsing succeeds
            signal.alarm(0)
        except TimeoutException:
            print(f"Timeout while parsing: {candidate}")
            return False
            
    except NameError:
        return False
    except SyntaxError:
        return False
    except Exception as e:
        print(f"Error: {e}")
        return False
    finally:
        # Ensure alarm is canceled
        signal.alarm(0)
    return True

if __name__ == '__main__':
    # Directory containing the variant result JSON files
    variants_dir = '/home/ubuntu/o1-replication-useast/MITIntegrationBee/MIT_variants'

    # List to store all variants
    TRAIN_QUESTIONS = []

    variant_files_and_dirs = list(Path(variants_dir).rglob('*'))
    variant_files = [f for f in variant_files_and_dirs if f.is_file()]
    
    # Iterate through all JSON files in the directory
    for filename in variant_files:
        if str(filename).endswith('.json'):
            file_path = os.path.join(variants_dir, filename)
            
            # Read and parse each JSON file
            with open(file_path, 'r') as f:
                variants_data = json.load(f)
                
                for arr in variants_data:
                    for variant in arr:
                        TRAIN_QUESTIONS.append(variant['variant'])
                        TRAIN_QUESTIONS.append(variant['original'])
    
    print(f"Number of training questions: {len(TRAIN_QUESTIONS)}")
   
    # Remove all duplicates in TRAIN_QUESTIONS and empty questions
    TRAIN_QUESTIONS = list(set(TRAIN_QUESTIONS))
    TRAIN_QUESTIONS = [q for q in TRAIN_QUESTIONS if q]

    FINAL_TRAIN_QUESTIONS = []

    # Remove all questions that don't have correct sympy formatting
    for question in tqdm(TRAIN_QUESTIONS, desc="Checking sympy formatting"):
        if sympy_correct_formatting(question):
            FINAL_TRAIN_QUESTIONS.append(question)

    print(f"Number of unique training questions: {len(TRAIN_QUESTIONS)}")
    print(f"Number of unique test questions: {len(TEST_QUESTIONS)}")

    variants_to_parquet(FINAL_TRAIN_QUESTIONS, TEST_QUESTIONS, '/home/ubuntu/o1-replication-useast/CustomTinyZero/data/ladder2.0_nosympy')